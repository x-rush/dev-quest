# Go æ€§èƒ½ä¼˜åŒ–æœ€ä½³å®è·µ

## ğŸ“š æ¦‚è¿°

Goè¯­è¨€ä»¥å…¶å‡ºè‰²çš„æ€§èƒ½ç‰¹æ€§è‘—ç§°ï¼Œä½†è¦å……åˆ†å‘æŒ¥å…¶æ€§èƒ½ä¼˜åŠ¿ï¼Œéœ€è¦æ·±å…¥ç†è§£Goçš„è¿è¡Œæœºåˆ¶å’Œä¼˜åŒ–æŠ€å·§ã€‚æœ¬æŒ‡å—å°†ä»PHPå¼€å‘è€…çš„è§’åº¦ï¼Œè¯¦ç»†ä»‹ç»Goåº”ç”¨çš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ã€‚

### ğŸ¯ å­¦ä¹ ç›®æ ‡
- æŒæ¡Goå†…å­˜ç®¡ç†å’Œä¼˜åŒ–
- å­¦ä¼šå¹¶å‘æ€§èƒ½ä¼˜åŒ–
- ç†è§£I/Oå’Œç½‘ç»œæ€§èƒ½ä¼˜åŒ–
- æŒæ¡æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–
- å­¦ä¼šä½¿ç”¨æ€§èƒ½åˆ†æå·¥å…·
- ç†è§£Goä¸PHPæ€§èƒ½å·®å¼‚çš„æ ¹æœ¬åŸå› 

## ğŸ”„ Go vs PHP æ€§èƒ½å¯¹æ¯”

### åŸºç¡€æ€§èƒ½å·®å¼‚
```go
// Go: ç¼–è¯‘å‹è¯­è¨€ï¼Œç›´æ¥è¿è¡Œæœºå™¨ç 
func fibonacci(n int) int {
    if n <= 1 {
        return n
    }
    return fibonacci(n-1) + fibonacci(n-2)
}

// ç¼–è¯‘åç›´æ¥è¿è¡Œï¼Œæ— è§£é‡Šå™¨å¼€é”€
// ç¼–è¯‘æ—¶ä¼˜åŒ–ï¼Œé™æ€ç±»å‹æ£€æŸ¥
```

```php
// PHP: è§£é‡Šå‹è¯­è¨€ï¼Œéœ€è¦è¿è¡Œæ—¶è§£æ
function fibonacci($n) {
    if ($n <= 1) {
        return $n;
    }
    return fibonacci($n - 1) + fibonacci($n - 2);
}

// æ¯æ¬¡è¯·æ±‚éƒ½éœ€è¦è§£é‡Šæ‰§è¡Œ
// åŠ¨æ€ç±»å‹æ£€æŸ¥ï¼Œè¿è¡Œæ—¶å¼€é”€è¾ƒå¤§
```

### å†…å­˜ç®¡ç†å·®å¼‚
```go
// Go: è‡ªåŠ¨åƒåœ¾å›æ”¶ï¼Œç¼–è¯‘æ—¶å†…å­˜åˆ†é…ä¼˜åŒ–
func processData(data []byte) {
    // æ ˆåˆ†é…ï¼ˆå°å¯¹è±¡ï¼‰
    var buffer [1024]byte

    // å †åˆ†é…ï¼ˆå¤§å¯¹è±¡æˆ–é€ƒé€¸åˆ†æï¼‰
    largeData := make([]byte, 1024*1024)

    // deferå»¶è¿Ÿé‡Šæ”¾
    defer func() {
        // æ¸…ç†èµ„æº
    }()
}
```

```php
// PHP: å¼•ç”¨è®¡æ•°åƒåœ¾å›æ”¶ï¼Œè¿è¡Œæ—¶å†…å­˜ç®¡ç†
function processData($data) {
    // æ‰€æœ‰å˜é‡éƒ½æ˜¯å¼•ç”¨ç±»å‹
    $buffer = str_repeat("x", 1024);
    $largeData = str_repeat("x", 1024 * 1024);

    // ä¾èµ–GCè‡ªåŠ¨å›æ”¶
}
```

## ğŸ“ å†…å­˜ä¼˜åŒ–

### 1. å†…å­˜åˆ†é…ä¼˜åŒ–

#### å‡å°‘å †åˆ†é…
```go
// ä¼˜åŒ–å‰ï¼šé¢‘ç¹çš„å†…å­˜åˆ†é…
func concatenateStrings(strings []string) string {
    result := ""
    for _, s := range strings {
        result += s // æ¯æ¬¡éƒ½åˆ†é…æ–°å†…å­˜
    }
    return result
}

// ä¼˜åŒ–åï¼šé¢„åˆ†é…å†…å­˜
func concatenateStringsOptimized(strings []string) string {
    // è®¡ç®—æ€»é•¿åº¦
    totalLen := 0
    for _, s := range strings {
        totalLen += len(s)
    }

    // é¢„åˆ†é…è¶³å¤Ÿç©ºé—´
    builder := strings.Builder{}
    builder.Grow(totalLen)

    for _, s := range strings {
        builder.WriteString(s)
    }

    return builder.String()
}
```

#### å¯¹è±¡æ± æ¨¡å¼
```go
package pool

import "sync"

type Object struct {
    Data []byte
}

type ObjectPool struct {
    pool sync.Pool
}

func NewObjectPool() *ObjectPool {
    return &ObjectPool{
        pool: sync.Pool{
            New: func() interface{} {
                return &Object{
                    Data: make([]byte, 1024),
                }
            },
        },
    }
}

func (p *ObjectPool) Get() *Object {
    return p.pool.Get().(*Object)
}

func (p *ObjectPool) Put(obj *Object) {
    // é‡ç½®å¯¹è±¡çŠ¶æ€
    obj.Data = obj.Data[:0]
    p.pool.Put(obj)
}

// ä½¿ç”¨ç¤ºä¾‹
func processWithPool() {
    pool := NewObjectPool()

    for i := 0; i < 1000; i++ {
        obj := pool.Get()

        // å¤„ç†æ•°æ®
        obj.Data = append(obj.Data, []byte("data")...)

        // å¤„ç†å®Œæˆåæ”¾å›æ± ä¸­
        pool.Put(obj)
    }
}
```

#### å†…å­˜å¤ç”¨
```go
// ä¼˜åŒ–å‰ï¼šæ¯æ¬¡åˆ›å»ºæ–°åˆ‡ç‰‡
func processChunks(chunks [][]byte) [][]byte {
    var result [][]byte
    for _, chunk := range chunks {
        processed := make([]byte, len(chunk))
        // å¤„ç†æ•°æ®...
        result = append(result, processed)
    }
    return result
}

// ä¼˜åŒ–åï¼šå¤ç”¨åˆ‡ç‰‡
func processChunksOptimized(chunks [][]byte) [][]byte {
    // é¢„åˆ†é…åˆ‡ç‰‡å®¹é‡
    result := make([][]byte, 0, len(chunks))

    // å¤ç”¨ç¼“å†²åŒº
    buffer := make([]byte, 0, 1024)

    for _, chunk := range chunks {
        // é‡ç½®ç¼“å†²åŒº
        buffer = buffer[:0]
        buffer = append(buffer, chunk...)

        // å¤„ç†æ•°æ®...

        // å¤åˆ¶ç»“æœ
        processed := make([]byte, len(buffer))
        copy(processed, buffer)
        result = append(result, processed)
    }

    return result
}
```

### 2. åƒåœ¾å›æ”¶ä¼˜åŒ–

#### GCå‹åŠ›æµ‹è¯•
```go
package gc

import (
    "runtime"
    "time"
)

type GCStats struct {
    NumGC        uint32
    PauseTotalNs uint64
    PauseNs      [256]uint64
}

func GetGCStats() GCStats {
    var stats GCStats
    runtime.ReadMemStats(&runtime.MemStats{
        NumGC:        &stats.NumGC,
        PauseTotalNs: &stats.PauseTotalNs,
        PauseNs:      stats.PauseNs,
    })
    return stats
}

// ç›‘æ§GCæ€§èƒ½
func MonitorGCPrint() {
    ticker := time.NewTicker(5 * time.Second)
    defer ticker.Stop()

    for range ticker.C {
        stats := GetGCStats()
        println("GC Stats:")
        println("  NumGC:", stats.NumGC)
        println("  PauseTotalNs:", stats.PauseTotalNs)
        println("  AvgPauseNs:", stats.PauseTotalNs/uint64(stats.NumGC))
    }
}

// ä¼˜åŒ–GCè°ƒä¼˜
func OptimizeGCSettings() {
    // è®¾ç½®GCç›®æ ‡ç™¾åˆ†æ¯”
    debug.SetGCPercent(20) // é»˜è®¤100ï¼Œå‡å°æ›´æ¿€è¿›å›æ”¶

    // è®¾ç½®æœ€å¤§å†…å­˜é™åˆ¶
    var m runtime.MemStats
    runtime.ReadMemStats(&m)

    // æ ¹æ®åº”ç”¨ç‰¹ç‚¹è°ƒæ•´
    if m.Sys > 1024*1024*1024 { // 1GB
        debug.SetMaxMemory(2 * 1024 * 1024 * 1024) // 2GBé™åˆ¶
    }
}
```

#### å†…å­˜æ³„æ¼æ£€æµ‹
```go
package memleak

import (
    "runtime"
    "time"
)

type MemoryLeakDetector struct {
    threshold   uint64
    lastCheck   uint64
    checkTicker *time.Ticker
    stopChan    chan struct{}
}

func NewMemoryLeakDetector(thresholdMB uint64) *MemoryLeakDetector {
    return &MemoryLeakDetector{
        threshold: thresholdMB * 1024 * 1024,
        stopChan:  make(chan struct{}),
    }
}

func (d *MemoryLeakDetector) Start() {
    d.lastCheck = d.getCurrentMemory()

    d.checkTicker = time.NewTicker(30 * time.Second)
    go func() {
        for {
            select {
            case <-d.checkTicker.C:
                d.checkMemory()
            case <-d.stopChan:
                return
            }
        }
    }()
}

func (d *MemoryLeakDetector) Stop() {
    if d.checkTicker != nil {
        d.checkTicker.Stop()
    }
    close(d.stopChan)
}

func (d *MemoryLeakDetector) getCurrentMemory() uint64 {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    return m.Alloc
}

func (d *MemoryLeakDetector) checkMemory() {
    current := d.getCurrentMemory()

    if current > d.lastCheck+d.threshold {
        println("Potential memory leak detected!")
        println("Previous:", d.lastCheck)
        println("Current:", current)
        println("Difference:", current-d.lastCheck)

        // æ‰“å°å †æ ˆä¿¡æ¯
        d.printStacks()
    }

    d.lastCheck = current
}

func (d *MemoryLeakDetector) printStacks() {
    buf := make([]byte, 1024*1024)
    n := runtime.Stack(buf, true)
    println(string(buf[:n]))
}
```

## ğŸ“ å¹¶å‘ä¼˜åŒ–

### 1. Goroutine ä¼˜åŒ–

#### æ§åˆ¶Goroutineæ•°é‡
```go
// ä¼˜åŒ–å‰ï¼šæ— é™åˆ¶åˆ›å»ºgoroutine
func processUnlimited(items []string) {
    for _, item := range items {
        go func(i string) {
            // å¤„ç†æ¯ä¸ªitem
            processItem(i)
        }(item)
    }
}

// ä¼˜åŒ–åï¼šä½¿ç”¨worker pool
func processWithWorkerPool(items []string, workers int) {
    // åˆ›å»ºä»»åŠ¡é€šé“
    taskChan := make(chan string, len(items))
    resultChan := make(chan string, len(items))

    // åˆ›å»ºworker pool
    var wg sync.WaitGroup
    for i := 0; i < workers; i++ {
        wg.Add(1)
        go func(workerID int) {
            defer wg.Done()
            for task := range taskChan {
                result := processItem(task)
                resultChan <- result
            }
        }(i)
    }

    // å‘é€ä»»åŠ¡
    go func() {
        for _, item := range items {
            taskChan <- item
        }
        close(taskChan)
    }()

    // ç­‰å¾…æ‰€æœ‰workerå®Œæˆ
    go func() {
        wg.Wait()
        close(resultChan)
    }()

    // æ”¶é›†ç»“æœ
    for result := range resultChan {
        // å¤„ç†ç»“æœ
        _ = result
    }
}

func processItem(item string) string {
    // æ¨¡æ‹Ÿå¤„ç†
    time.Sleep(10 * time.Millisecond)
    return "processed:" + item
}
```

#### ä½¿ç”¨sync.Poolå‡å°‘GCå‹åŠ›
```go
package worker

import (
    "sync"
    "time"
)

type Task struct {
    ID    string
    Data  []byte
    Result chan<- *Result
}

type Result struct {
    ID   string
    Data []byte
}

type WorkerPool struct {
    workers   int
    taskQueue chan *Task
    workerPool sync.Pool
    wg        sync.WaitGroup
    quit      chan struct{}
}

func NewWorkerPool(workers, queueSize int) *WorkerPool {
    return &WorkerPool{
        workers:   workers,
        taskQueue: make(chan *Task, queueSize),
        workerPool: sync.Pool{
            New: func() interface{} {
                return &worker{
                    id:         time.Now().UnixNano(),
                    taskQueue:  make(chan *Task, 100),
                }
            },
        },
        quit: make(chan struct{}),
    }
}

func (p *WorkerPool) Start() {
    for i := 0; i < p.workers; i++ {
        p.wg.Add(1)
        go p.worker()
    }
}

func (p *WorkerPool) Stop() {
    close(p.quit)
    p.wg.Wait()
}

func (p *WorkerPool) Submit(task *Task) {
    select {
    case p.taskQueue <- task:
    default:
        // é˜Ÿåˆ—æ»¡ï¼Œæ‹’ç»æˆ–ç­‰å¾…
        task.Result <- &Result{ID: task.ID, Data: []byte("queue full")}
    }
}

func (p *WorkerPool) worker() {
    defer p.wg.Done()

    // ä»poolè·å–worker
    w := p.workerPool.Get().(*worker)
    defer p.workerPool.Put(w)

    for {
        select {
        case task := <-p.taskQueue:
            w.process(task)
        case <-p.quit:
            return
        }
    }
}

type worker struct {
    id        int64
    taskQueue chan *Task
}

func (w *worker) process(task *Task) {
    // å¤„ç†ä»»åŠ¡
    result := &Result{
        ID:   task.ID,
        Data: []byte("processed:" + task.ID),
    }

    // è¿”å›ç»“æœ
    task.Result <- result
}
```

### 2. å¹¶å‘æ¨¡å¼ä¼˜åŒ–

#### ä½¿ç”¨Contextè¿›è¡Œè¶…æ—¶æ§åˆ¶
```go
package context

import (
    "context"
    "net/http"
    "time"
)

func fetchWithTimeout(ctx context.Context, url string) (*http.Response, error) {
    // åˆ›å»ºå¸¦è¶…æ—¶çš„context
    ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
    defer cancel()

    // åˆ›å»ºè¯·æ±‚
    req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
    if err != nil {
        return nil, err
    }

    // å‘é€è¯·æ±‚
    client := &http.Client{}
    return client.Do(req)
}

// å¹¶å‘è¯·æ±‚ä¼˜åŒ–
func fetchMultiple(urls []string) map[string]*http.Response {
    ctx := context.Background()
    results := make(map[string]*http.Response)
    resultChan := make(chan struct {
        url    string
        resp   *http.Response
        err    error
    }, len(urls))

    var wg sync.WaitGroup
    for _, url := range urls {
        wg.Add(1)
        go func(u string) {
            defer wg.Done()

            resp, err := fetchWithTimeout(ctx, u)
            resultChan <- struct {
                url    string
                resp   *http.Response
                err    error
            }{u, resp, err}
        }(url)
    }

    // ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆ
    go func() {
        wg.Wait()
        close(resultChan)
    }()

    // æ”¶é›†ç»“æœ
    for result := range resultChan {
        if result.err == nil {
            results[result.url] = result.resp
        }
    }

    return results
}
```

#### ä½¿ç”¨errgroupè¿›è¡Œé”™è¯¯å¤„ç†
```go
package errgroup

import (
    "context"
    "errors"
    "fmt"
    "sync"
)

type Group struct {
    cancel func()
    wg     sync.WaitGroup
    err    error
}

func WithContext(ctx context.Context) (*Group, context.Context) {
    ctx, cancel := context.WithCancel(ctx)
    return &Group{cancel: cancel}, ctx
}

func (g *Group) Go(f func() error) {
    g.wg.Add(1)
    go func() {
        defer g.wg.Done()

        if err := f(); err != nil {
            g.err = err
            if g.cancel != nil {
                g.cancel()
            }
        }
    }()
}

func (g *Group) Wait() error {
    g.wg.Wait()
    return g.err
}

// ä½¿ç”¨ç¤ºä¾‹
func processMultipleOperations() error {
    g, ctx := WithContext(context.Background())

    // å¹¶å‘æ‰§è¡Œå¤šä¸ªæ“ä½œ
    g.Go(func() error {
        return fetchUserData(ctx)
    })

    g.Go(func() error {
        return fetchOrderData(ctx)
    })

    g.Go(func() error {
        return fetchProductData(ctx)
    })

    // ç­‰å¾…æ‰€æœ‰æ“ä½œå®Œæˆ
    return g.Wait()
}

func fetchUserData(ctx context.Context) error {
    // æ¨¡æ‹Ÿç”¨æˆ·æ•°æ®è·å–
    select {
    case <-time.After(100 * time.Millisecond):
        return nil
    case <-ctx.Done():
        return ctx.Err()
    }
}

func fetchOrderData(ctx context.Context) error {
    // æ¨¡æ‹Ÿè®¢å•æ•°æ®è·å–
    select {
    case <-time.After(150 * time.Millisecond):
        return errors.New("failed to fetch orders")
    case <-ctx.Done():
        return ctx.Err()
    }
}

func fetchProductData(ctx context.Context) error {
    // æ¨¡æ‹Ÿäº§å“æ•°æ®è·å–
    select {
    case <-time.After(200 * time.Millisecond):
        return nil
    case <-ctx.Done():
        return ctx.Err()
    }
}
```

## ğŸ“ I/Oå’Œç½‘ç»œä¼˜åŒ–

### 1. ç½‘ç»œä¼˜åŒ–

#### è¿æ¥æ± å¤ç”¨
```go
package http

import (
    "net/http"
    "sync"
    "time"
)

type HTTPClientPool struct {
    clients map[string]*http.Client
    mu      sync.RWMutex
}

func NewHTTPClientPool() *HTTPClientPool {
    return &HTTPClientPool{
        clients: make(map[string]*http.Client),
    }
}

func (p *HTTPClientPool) GetClient(timeout time.Duration) *http.Client {
    key := timeout.String()

    p.mu.RLock()
    if client, exists := p.clients[key]; exists {
        p.mu.RUnlock()
        return client
    }
    p.mu.RUnlock()

    p.mu.Lock()
    defer p.mu.Unlock()

    // åŒé‡æ£€æŸ¥
    if client, exists := p.clients[key]; exists {
        return client
    }

    // åˆ›å»ºæ–°client
    client := &http.Client{
        Timeout: timeout,
        Transport: &http.Transport{
            MaxIdleConns:        100,
            MaxIdleConnsPerHost: 10,
            IdleConnTimeout:     30 * time.Second,
        },
    }

    p.clients[key] = client
    return client
}

// ä½¿ç”¨ç¤ºä¾‹
var httpClientPool = NewHTTPClientPool()

func makeRequest(url string) (*http.Response, error) {
    client := httpClientPool.GetClient(10 * time.Second)
    return client.Get(url)
}
```

#### æ‰¹é‡è¯·æ±‚å¤„ç†
```go
package batch

import (
    "context"
    "sync"
    "time"
)

type BatchProcessor struct {
    batchSize int
    timeout   time.Duration
    buffer    []interface{}
    processor func([]interface{}) error
    mu        sync.Mutex
    ticker    *time.Ticker
    quit      chan struct{}
}

func NewBatchProcessor(batchSize int, timeout time.Duration, processor func([]interface{}) error) *BatchProcessor {
    return &BatchProcessor{
        batchSize: batchSize,
        timeout:   timeout,
        buffer:    make([]interface{}, 0, batchSize),
        processor: processor,
        quit:      make(chan struct{}),
    }
}

func (p *BatchProcessor) Start() {
    p.ticker = time.NewTicker(p.timeout)
    go func() {
        for {
            select {
            case <-p.ticker.C:
                p.flush()
            case <-p.quit:
                p.flush()
                return
            }
        }
    }()
}

func (p *BatchProcessor) Stop() {
    close(p.quit)
    if p.ticker != nil {
        p.ticker.Stop()
    }
}

func (p *BatchProcessor) Add(item interface{}) error {
    p.mu.Lock()
    defer p.mu.Unlock()

    p.buffer = append(p.buffer, item)

    if len(p.buffer) >= p.batchSize {
        return p.flush()
    }

    return nil
}

func (p *BatchProcessor) flush() error {
    p.mu.Lock()
    defer p.mu.Unlock()

    if len(p.buffer) == 0 {
        return nil
    }

    batch := make([]interface{}, len(p.buffer))
    copy(batch, p.buffer)
    p.buffer = p.buffer[:0]

    return p.processor(batch)
}

// ä½¿ç”¨ç¤ºä¾‹
func processBatchItems() {
    processor := NewBatchProcessor(100, 5*time.Second, func(items []interface{}) error {
        println("Processing batch of", len(items), "items")
        // æ‰¹é‡å¤„ç†é€»è¾‘
        return nil
    })

    processor.Start()
    defer processor.Stop()

    // æ·»åŠ é¡¹ç›®
    for i := 0; i < 250; i++ {
        processor.Add(i)
    }
}
```

### 2. æ–‡ä»¶I/Oä¼˜åŒ–

#### ç¼“å†²I/O
```go
package io

import (
    "bufio"
    "os"
)

// ä¼˜åŒ–å‰ï¼šç›´æ¥æ–‡ä»¶æ“ä½œ
func readFileDirect(filename string) ([]string, error) {
    file, err := os.Open(filename)
    if err != nil {
        return nil, err
    }
    defer file.Close()

    var lines []string
    buffer := make([]byte, 1024)

    for {
        n, err := file.Read(buffer)
        if err != nil {
            break
        }

        // å¤„ç†æ•°æ®
        lines = append(lines, string(buffer[:n]))
    }

    return lines, nil
}

// ä¼˜åŒ–åï¼šç¼“å†²è¯»å–
func readBuffered(filename string) ([]string, error) {
    file, err := os.Open(filename)
    if err != nil {
        return nil, err
    }
    defer file.Close()

    scanner := bufio.NewScanner(file)
    var lines []string

    for scanner.Scan() {
        lines = append(lines, scanner.Text())
    }

    if err := scanner.Err(); err != nil {
        return nil, err
    }

    return lines, nil
}

// å¹¶å‘æ–‡ä»¶å¤„ç†
func processFilesConcurrently(filenames []string) error {
    const workers = 5
    jobs := make(chan string, len(filenames))
    results := make(chan error, len(filenames))

    var wg sync.WaitGroup
    for i := 0; i < workers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for filename := range jobs {
                err := processFile(filename)
                results <- err
            }
        }()
    }

    // å‘é€ä»»åŠ¡
    go func() {
        for _, filename := range filenames {
            jobs <- filename
        }
        close(jobs)
    }()

    // ç­‰å¾…å®Œæˆ
    go func() {
        wg.Wait()
        close(results)
    }()

    // æ”¶é›†ç»“æœ
    for err := range results {
        if err != nil {
            return err
        }
    }

    return nil
}

func processFile(filename string) error {
    // æ–‡ä»¶å¤„ç†é€»è¾‘
    _, err := readBuffered(filename)
    return err
}
```

## ğŸ“ æ•°æ®åº“ä¼˜åŒ–

### 1. è¿æ¥æ± ä¼˜åŒ–

#### æ•°æ®åº“è¿æ¥æ± é…ç½®
```go
package database

import (
    "time"
    "gorm.io/driver/postgres"
    "gorm.io/gorm"
    "gorm.io/gorm/logger"
)

type DBConfig struct {
    Host            string
    Port            int
    User            string
    Password        string
    DBName          string
    MaxIdleConns    int
    MaxOpenConns    int
    ConnMaxLifetime time.Duration
    ConnMaxIdleTime time.Duration
}

func InitDB(config DBConfig) (*gorm.DB, error) {
    dsn := buildDSN(config)

    db, err := gorm.Open(postgres.Open(dsn), &gorm.Config{
        Logger: logger.Default.LogMode(logger.Info),
    })
    if err != nil {
        return nil, err
    }

    // è·å–åº•å±‚sql.DB
    sqlDB, err := db.DB()
    if err != nil {
        return nil, err
    }

    // é…ç½®è¿æ¥æ± 
    sqlDB.SetMaxIdleConns(config.MaxIdleConns)
    sqlDB.SetMaxOpenConns(config.MaxOpenConns)
    sqlDB.SetConnMaxLifetime(config.ConnMaxLifetime)
    sqlDB.SetConnMaxIdleTime(config.ConnMaxIdleTime)

    return db, nil
}

func buildDSN(config DBConfig) string {
    return fmt.Sprintf("host=%s user=%s password=%s dbname=%s port=%d sslmode=disable TimeZone=Asia/Shanghai",
        config.Host, config.User, config.Password, config.DBName, config.Port)
}

// è¿æ¥æ± ç›‘æ§
type ConnectionPoolMonitor struct {
    db *gorm.DB
}

func NewConnectionPoolMonitor(db *gorm.DB) *ConnectionPoolMonitor {
    return &ConnectionPoolMonitor{db: db}
}

func (m *ConnectionPoolMonitor) GetStats() map[string]interface{} {
    sqlDB, _ := m.db.DB()
    stats := sqlDB.Stats()

    return map[string]interface{}{
        "open_connections":     stats.OpenConnections,
        "in_use":              stats.InUse,
        "idle":                stats.Idle,
        "wait_count":          stats.WaitCount,
        "wait_duration":       stats.WaitDuration,
        "max_idle_closed":     stats.MaxIdleClosed,
        "max_lifetime_closed":  stats.MaxLifetimeClosed,
    }
}

func (m *ConnectionPoolMonitor) PrintStats() {
    stats := m.GetStats()
    println("Database Connection Pool Stats:")
    for key, value := range stats {
        printf("  %s: %v\n", key, value)
    }
}
```

### 2. æŸ¥è¯¢ä¼˜åŒ–

#### æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–
```go
package repository

import (
    "context"
    "gorm.io/gorm"
)

type UserRepository struct {
    db *gorm.DB
}

// ä¼˜åŒ–å‰ï¼šN+1æŸ¥è¯¢é—®é¢˜
func (r *UserRepository) GetUsersWithPostsBad() ([]User, error) {
    var users []User
    if err := r.db.Find(&users).Error; err != nil {
        return nil, err
    }

    // å¯¹æ¯ä¸ªç”¨æˆ·éƒ½å‘èµ·ä¸€æ¬¡æŸ¥è¯¢
    for i := range users {
        var posts []Post
        if err := r.db.Where("user_id = ?", users[i].ID).Find(&posts).Error; err != nil {
            return nil, err
        }
        users[i].Posts = posts
    }

    return users, nil
}

// ä¼˜åŒ–åï¼šé¢„åŠ è½½å…³è”
func (r *UserRepository) GetUsersWithPostsGood() ([]User, error) {
    var users []User
    // ä½¿ç”¨Preloadä¸€æ¬¡æ€§åŠ è½½å…³è”æ•°æ®
    if err := r.db.Preload("Posts").Find(&users).Error; err != nil {
        return nil, err
    }
    return users, nil
}

// æ‰¹é‡æ’å…¥ä¼˜åŒ–
func (r *UserRepository) BatchInsertUsers(users []User) error {
    // ä¼˜åŒ–å‰ï¼šé€æ¡æ’å…¥
    // for _, user := range users {
    //     if err := r.db.Create(&user).Error; err != nil {
    //         return err
    //     }
    // }

    // ä¼˜åŒ–åï¼šæ‰¹é‡æ’å…¥
    if len(users) == 0 {
        return nil
    }

    // åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å•æ¬¡æ’å…¥æ•°æ®é‡è¿‡å¤§
    batchSize := 1000
    for i := 0; i < len(users); i += batchSize {
        end := i + batchSize
        if end > len(users) {
            end = len(users)
        }

        batch := users[i:end]
        if err := r.db.CreateInBatches(batch, batchSize).Error; err != nil {
            return err
        }
    }

    return nil
}

// äº‹åŠ¡ä¼˜åŒ–
func (r *UserRepository) TransferFunds(ctx context.Context, fromID, toID uint, amount float64) error {
    return r.db.Transaction(func(tx *gorm.DB) error {
        // æ‰£é™¤å‘é€æ–¹ä½™é¢
        if err := tx.Model(&User{}).Where("id = ?", fromID).
            Update("balance", gorm.Expr("balance - ?", amount)).Error; err != nil {
            return err
        }

        // å¢åŠ æ¥æ”¶æ–¹ä½™é¢
        if err := tx.Model(&User{}).Where("id = ?", toID).
            Update("balance", gorm.Expr("balance + ?", amount)).Error; err != nil {
            return err
        }

        return nil
    })
}
```

## ğŸ“ æ€§èƒ½åˆ†æå·¥å…·

### 1. pprof ä½¿ç”¨

#### CPUæ€§èƒ½åˆ†æ
```go
package pprof

import (
    "os"
    "runtime/pprof"
    "time"
)

type Profiler struct {
    cpuProfile *os.File
    memProfile *os.File
}

func NewProfiler() *Profiler {
    return &Profiler{}
}

func (p *Profiler) StartCPUProfile(filename string) error {
    var err error
    p.cpuProfile, err = os.Create(filename)
    if err != nil {
        return err
    }

    return pprof.StartCPUProfile(p.cpuProfile)
}

func (p *Profiler) StopCPUProfile() {
    if p.cpuProfile != nil {
        pprof.StopCPUProfile()
        p.cpuProfile.Close()
        p.cpuProfile = nil
    }
}

func (p *Profiler) WriteMemProfile(filename string) error {
    var err error
    p.memProfile, err = os.Create(filename)
    if err != nil {
        return err
    }

    // è·å–å½“å‰å †å†…å­˜ä¿¡æ¯
    var m runtime.MemStats
    runtime.ReadMemStats(&m)

    // å†™å…¥å†…å­˜åˆ†ææ•°æ®
    return pprof.WriteHeapProfile(p.memProfile)
}

func (p *Profiler) Close() {
    p.StopCPUProfile()
    if p.memProfile != nil {
        p.memProfile.Close()
        p.memProfile = nil
    }
}

// ä½¿ç”¨ç¤ºä¾‹
func profileApplication() {
    profiler := NewProfiler()

    // å¼€å§‹CPUåˆ†æ
    if err := profiler.StartCPUProfile("cpu.prof"); err != nil {
        panic(err)
    }

    // è¿è¡Œåº”ç”¨ç¨‹åº
    runApplication()

    // åœæ­¢CPUåˆ†æ
    profiler.StopCPUProfile()

    // å†™å…¥å†…å­˜åˆ†æ
    if err := profiler.WriteMemProfile("mem.prof"); err != nil {
        panic(err)
    }

    profiler.Close()
}

func runApplication() {
    // æ¨¡æ‹Ÿåº”ç”¨ç¨‹åºè¿è¡Œ
    for i := 0; i < 1000000; i++ {
        fibonacci(30)
    }
}

func fibonacci(n int) int {
    if n <= 1 {
        return n
    }
    return fibonacci(n-1) + fibonacci(n-2)
}
```

### 2. è‡ªå®šä¹‰æ€§èƒ½ç›‘æ§

#### æ€§èƒ½æŒ‡æ ‡æ”¶é›†
```go
package metrics

import (
    "runtime"
    "sync"
    "time"
)

type PerformanceMetrics struct {
    mu           sync.RWMutex
    goroutines   int
    memoryUsage  uint64
    gcStats      GCStats
    responseTime map[string]time.Duration
}

type GCStats struct {
    NumGC        uint32
    PauseTotalNs uint64
    PauseNs      [256]uint64
}

type MetricsCollector struct {
    metrics      *PerformanceMetrics
    interval     time.Duration
    stopChan     chan struct{}
}

func NewMetricsCollector(interval time.Duration) *MetricsCollector {
    return &MetricsCollector{
        metrics: &PerformanceMetrics{
            responseTime: make(map[string]time.Duration),
        },
        interval: interval,
        stopChan: make(chan struct{}),
    }
}

func (c *MetricsCollector) Start() {
    ticker := time.NewTicker(c.interval)
    go func() {
        for {
            select {
            case <-ticker.C:
                c.collectMetrics()
            case <-c.stopChan:
                return
            }
        }
    }()
}

func (c *MetricsCollector) Stop() {
    close(c.stopChan)
}

func (c *MetricsCollector) collectMetrics() {
    c.metrics.mu.Lock()
    defer c.metrics.mu.Unlock()

    // æ”¶é›†goroutineæ•°é‡
    c.metrics.goroutines = runtime.NumGoroutine()

    // æ”¶é›†å†…å­˜ä½¿ç”¨
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    c.metrics.memoryUsage = m.Alloc

    // æ”¶é›†GCç»Ÿè®¡
    c.metrics.gcStats = GCStats{
        NumGC:        m.NumGC,
        PauseTotalNs: m.PauseTotalNs,
    }
    copy(c.metrics.gcStats.PauseNs[:], m.PauseNs[:])
}

func (c *MetricsCollector) RecordResponseTime(endpoint string, duration time.Duration) {
    c.metrics.mu.Lock()
    defer c.metrics.mu.Unlock()

    c.metrics.responseTime[endpoint] = duration
}

func (c *MetricsCollector) GetMetrics() PerformanceMetrics {
    c.metrics.mu.RLock()
    defer c.metrics.mu.RUnlock()

    return *c.metrics
}

// æ€§èƒ½åˆ†æå™¨
type PerformanceAnalyzer struct {
    collector *MetricsCollector
    threshold time.Duration
}

func NewPerformanceAnalyzer(collector *MetricsCollector, threshold time.Duration) *PerformanceAnalyzer {
    return &PerformanceAnalyzer{
        collector: collector,
        threshold: threshold,
    }
}

func (a *PerformanceAnalyzer) Analyze() []string {
    metrics := a.collector.GetMetrics()
    var issues []string

    // æ£€æŸ¥goroutineæ•°é‡
    if metrics.goroutines > 1000 {
        issues = append(issues, fmt.Sprintf("High goroutine count: %d", metrics.goroutines))
    }

    // æ£€æŸ¥å†…å­˜ä½¿ç”¨
    if metrics.memoryUsage > 100*1024*1024 { // 100MB
        issues = append(issues, fmt.Sprintf("High memory usage: %d MB", metrics.memoryUsage/1024/1024))
    }

    // æ£€æŸ¥GCé¢‘ç‡
    if metrics.gcStats.NumGC > 100 {
        issues = append(issues, fmt.Sprintf("High GC frequency: %d", metrics.gcStats.NumGC))
    }

    // æ£€æŸ¥å“åº”æ—¶é—´
    for endpoint, duration := range metrics.responseTime {
        if duration > a.threshold {
            issues = append(issues, fmt.Sprintf("Slow endpoint %s: %v", endpoint, duration))
        }
    }

    return issues
}
```

## ğŸ§ª å®è·µç»ƒä¹ 

### ç»ƒä¹ 1: å®Œæ•´çš„æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹
```go
// main.go
package main

import (
    "context"
    "fmt"
    "sync"
    "time"

    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promhttp"
)

type PerformanceOptimizedServer struct {
    requestCounter  prometheus.Counter
    requestDuration prometheus.Histogram
    workerPool     *WorkerPool
    cache         *Cache
}

func NewPerformanceOptimizedServer() *PerformanceOptimizedServer {
    return &PerformanceOptimizedServer{
        requestCounter: prometheus.NewCounter(prometheus.CounterOpts{
            Name: "requests_total",
            Help: "Total number of requests",
        }),
        requestDuration: prometheus.NewHistogram(prometheus.HistogramOpts{
            Name:    "request_duration_seconds",
            Help:    "Request duration in seconds",
            Buckets: []float64{0.1, 0.5, 1, 2.5, 5},
        }),
        workerPool: NewWorkerPool(10, 100),
        cache:      NewCache(1000),
    }
}

func (s *PerformanceOptimizedServer) HandleRequest(ctx context.Context, req *Request) (*Response, error) {
    start := time.Now()
    defer func() {
        s.requestCounter.Inc()
        s.requestDuration.Observe(time.Since(start).Seconds())
    }()

    // æ£€æŸ¥ç¼“å­˜
    if cached, found := s.cache.Get(req.ID); found {
        return cached.(*Response), nil
    }

    // ä½¿ç”¨worker poolå¤„ç†
    resultChan := make(chan *Response, 1)
    errChan := make(chan error, 1)

    task := &Task{
        ID:     req.ID,
        Data:   req.Data,
        Result: resultChan,
        Error:  errChan,
    }

    if err := s.workerPool.Submit(task); err != nil {
        return nil, err
    }

    select {
    case result := <-resultChan:
        // ç¼“å­˜ç»“æœ
        s.cache.Set(req.ID, result, 5*time.Minute)
        return result, nil
    case err := <-errChan:
        return nil, err
    case <-ctx.Done():
        return nil, ctx.Err()
    }
}

// ç¼“å­˜å®ç°
type Cache struct {
    items map[string]interface{}
    mu    sync.RWMutex
    size  int
}

func NewCache(size int) *Cache {
    return &Cache{
        items: make(map[string]interface{}),
        size:  size,
    }
}

func (c *Cache) Get(key string) (interface{}, bool) {
    c.mu.RLock()
    defer c.mu.RUnlock()

    item, exists := c.items[key]
    return item, exists
}

func (c *Cache) Set(key string, value interface{}, ttl time.Duration) {
    c.mu.Lock()
    defer c.mu.Unlock()

    // å¦‚æœç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€æ—§çš„é¡¹
    if len(c.items) >= c.size {
        // ç®€å•çš„LRUå®ç°
        for k := range c.items {
            delete(c.items, k)
            break
        }
    }

    c.items[key] = value
}

func main() {
    server := NewPerformanceOptimizedServer()

    // å¯åŠ¨ç›‘æ§
    http.Handle("/metrics", promhttp.Handler())
    go http.ListenAndServe(":9090", nil)

    // å¤„ç†è¯·æ±‚
    for i := 0; i < 10000; i++ {
        req := &Request{
            ID:   fmt.Sprintf("req-%d", i),
            Data: fmt.Sprintf("data-%d", i),
        }

        resp, err := server.HandleRequest(context.Background(), req)
        if err != nil {
            fmt.Printf("Error: %v\n", err)
            continue
        }

        fmt.Printf("Processed: %s\n", resp.Data)
    }
}
```

## ğŸ“‹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£å†…å­˜ç®¡ç†ä¼˜åŒ–
- [ ] æŒæ¡å¹¶å‘ç¼–ç¨‹ä¼˜åŒ–
- [ ] å­¦ä¼šI/Oå’Œç½‘ç»œä¼˜åŒ–
- [ ] ç†è§£æ•°æ®åº“ä¼˜åŒ–ç­–ç•¥
- [ ] æŒæ¡æ€§èƒ½åˆ†æå·¥å…·
- [ ] å­¦ä¼šä½¿ç”¨ç¼“å­˜
- [ ] ç†è§£Goæ€§èƒ½ç‰¹æ€§
- [ ] æŒæ¡æœ€ä½³å®è·µ

## ğŸš€ ä¸‹ä¸€æ­¥

æŒæ¡æ€§èƒ½ä¼˜åŒ–åï¼Œä½ å¯ä»¥ç»§ç»­å­¦ä¹ ï¼š
- **é«˜çº§å¹¶å‘æ¨¡å¼**: å¤æ‚å¹¶å‘åœºæ™¯å¤„ç†
- **åˆ†å¸ƒå¼ç³»ç»Ÿ**: åˆ†å¸ƒå¼æ€§èƒ½ä¼˜åŒ–
- **å®¹å™¨åŒ–ä¼˜åŒ–**: Dockerå’ŒK8sæ€§èƒ½è°ƒä¼˜
- **AIOps**: æ™ºèƒ½æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

---

**å­¦ä¹ æç¤º**: Goçš„æ€§èƒ½ä¼˜åŒ–éœ€è¦æ·±å…¥ç†è§£å…¶è¿è¡Œæœºåˆ¶ã€‚ä¸PHPä¸åŒï¼ŒGoæ˜¯ç¼–è¯‘å‹è¯­è¨€ï¼Œå¯ä»¥é€šè¿‡ç¼–è¯‘æ—¶ä¼˜åŒ–å’Œè¿è¡Œæ—¶è°ƒä¼˜æ¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚åˆç†ä½¿ç”¨å¹¶å‘å’Œå†…å­˜ç®¡ç†æ˜¯Goæ€§èƒ½ä¼˜åŒ–çš„å…³é”®ã€‚

*æœ€åæ›´æ–°: 2025å¹´9æœˆ*